import requests

#TODO DOMAIN AND FILE CRAWLER!

def request(url):
    try:
        get_response = requests.get("http://" + url)
        return get_response
    except requests.exceptions.ConnectionError:
        pass

target_url  = "10.0.2.6/mutillidae/"

with open("dirs.list", "r") as wordlist_file:
    i = 0
    for line in wordlist_file:
        word = line.strip()
        test_url = target_url + "/" + word;
        response = request(test_url)
        if response:
            print("[+] Discovered URL --> " + test_url)
            i += 1

    if i <= 0:
        print("[-] No URLS Found...")